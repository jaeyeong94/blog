---
title: 'React Server Components 스트리밍과 Suspense 경계 전략으로 웹 앱 성능 극대화하기'
excerpt: 'RSC 스트리밍 아키텍처, Suspense 경계 설계 패턴, 병렬 데이터 페칭을 활용하여 TTI와 LCP를 극적으로 개선하는 프로덕션 전략을 심층 분석합니다.'
date: '2026-02-23'
category: 'FRONTEND'
tags: ['React', 'Server Components', 'Streaming', 'Suspense', 'Performance', 'Next.js']
featured: false
---

# React Server Components 스트리밍과 Suspense 경계 전략으로 웹 앱 성능 극대화하기

## 서론: 왜 스트리밍이 프론트엔드의 게임 체인저인가

2025년을 지나 2026년에 접어든 지금, React Server Components(RSC)는 더 이상 실험적 기능이 아닙니다. Next.js 15의 App Router를 시작으로 RSC는 프로덕션 애플리케이션의 기본 렌더링 전략으로 자리 잡았습니다. 하지만 많은 개발자들이 RSC를 도입하면서 한 가지 핵심적인 요소를 간과하고 있습니다. 바로 **스트리밍(Streaming)**입니다.

전통적인 서버 사이드 렌더링(SSR)은 서버에서 전체 HTML을 생성한 뒤 한 번에 클라이언트로 전송합니다. 이 방식의 근본적 문제는 **가장 느린 데이터 소스가 전체 응답 시간을 결정한다는 것**입니다. 대시보드 페이지에서 사용자 프로필(50ms), 알림 목록(200ms), 분석 차트(2초)를 렌더링한다면, 사용자는 2초가 지나야 아무것도 볼 수 없습니다.

RSC 스트리밍은 이 패러다임을 완전히 뒤집습니다. 준비된 부분부터 즉시 전송하고, 나머지는 점진적으로 채워 넣습니다. 사용자는 50ms 만에 프로필을 보고, 200ms에 알림을 확인하며, 분석 차트는 로딩 스켈레톤에서 실제 데이터로 자연스럽게 전환됩니다. 이것은 단순한 최적화가 아니라, 사용자 경험의 본질적 변화입니다.

이 글에서는 RSC 스트리밍의 내부 동작 원리부터 Suspense 경계 설계 전략, 병렬 데이터 페칭 패턴, 그리고 프로덕션에서 LCP와 TTI를 극적으로 개선한 실전 사례까지 깊이 있게 다루겠습니다. 코드 예제는 Next.js 15 App Router를 기반으로 하지만, RSC 프로토콜을 구현하는 모든 프레임워크에 적용 가능한 아키텍처 패턴을 제시합니다.

## RSC 스트리밍의 내부 동작 원리

### RSC 페이로드와 청크 스트리밍

RSC는 기존 SSR과 다른 방식으로 동작합니다. 서버에서 컴포넌트를 렌더링하면 HTML이 아닌 **RSC 페이로드**라는 특수한 직렬화 형식을 생성합니다. 이 페이로드는 React 컴포넌트 트리의 "청사진"으로, 브라우저의 React 런타임이 이를 해석하여 DOM을 구성합니다.

스트리밍의 핵심은 이 페이로드를 **청크(chunk)** 단위로 분할하여 전송한다는 점입니다. HTTP/1.1의 `Transfer-Encoding: chunked`나 HTTP/2의 프레임 멀티플렉싱을 활용하여, 서버는 렌더링이 완료된 부분부터 순차적으로 클라이언트에 전송합니다.

```typescript
// 서버 컴포넌트 - 각 컴포넌트가 독립적으로 렌더링됨
// app/dashboard/page.tsx
import { Suspense } from 'react';
import { UserProfile } from './user-profile';
import { NotificationList } from './notifications';
import { AnalyticsChart } from './analytics';
import { DashboardSkeleton } from './skeletons';

export default function DashboardPage() {
  return (
    <div className="dashboard-grid">
      {/* 즉시 렌더링 - 정적 셸 */}
      <header className="dashboard-header">
        <h1>대시보드</h1>
        <nav>{/* 네비게이션은 즉시 전송됨 */}</nav>
      </header>

      {/* 각 Suspense 경계가 독립적 스트리밍 단위 */}
      <Suspense fallback={<ProfileSkeleton />}>
        <UserProfile />
      </Suspense>

      <Suspense fallback={<NotificationSkeleton />}>
        <NotificationList />
      </Suspense>

      <Suspense fallback={<ChartSkeleton />}>
        <AnalyticsChart />
      </Suspense>
    </div>
  );
}
```

이 코드에서 React는 먼저 정적 HTML 셸(헤더, 네비게이션)과 세 개의 fallback 스켈레톤을 즉시 클라이언트로 전송합니다. 그 후 각 서버 컴포넌트의 데이터 페칭이 완료될 때마다, 해당 Suspense 경계의 실제 콘텐츠를 추가 청크로 전송합니다.

### 스트림 구조와 대체 메커니즘

브라우저 측에서 React는 스트리밍된 HTML에 포함된 인라인 `<script>` 태그를 통해 Suspense 경계를 교체합니다. 구체적으로 동작을 살펴보면 다음과 같습니다:

```html
<!-- 초기 전송: 폴백 UI와 숨겨진 템플릿 -->
<!--$?-->
<template id="B:0"></template>
<div class="skeleton profile-skeleton">로딩 중...</div>
<!--/$-->

<!-- 데이터 준비 완료 후 추가 전송 -->
<div hidden id="S:0">
  <div class="user-profile">
    <img src="/avatar.jpg" alt="사용자" />
    <h2>김개발</h2>
    <p>Senior Frontend Engineer</p>
  </div>
</div>
<script>
  // React가 자동으로 실행: 스켈레톤을 실제 콘텐츠로 교체
  $RC("B:0", "S:0");
</script>
```

이 과정은 JavaScript 하이드레이션 없이도 작동하며, 브라우저는 각 청크를 수신할 때마다 점진적으로 DOM을 업데이트합니다. **이것이 바로 RSC 스트리밍이 전통적 SSR보다 빠른 핵심 이유입니다.** 전체 페이지를 기다리지 않고, 준비된 부분부터 사용자에게 보여줄 수 있기 때문입니다.

## Suspense 경계 설계 전략

### 경계의 단위를 어떻게 나눌 것인가

Suspense 경계 설계는 RSC 스트리밍 성능의 핵심입니다. 너무 세분화하면 폴백 UI가 과도하게 깜빡거리고, 너무 크게 묶으면 스트리밍의 장점을 잃습니다. 올바른 경계 설계에는 세 가지 원칙이 있습니다.

**원칙 1: 데이터 의존성 기준으로 분리합니다.** 서로 다른 API나 데이터베이스에서 데이터를 가져오는 컴포넌트는 별도의 Suspense 경계로 감싸야 합니다. 같은 데이터 소스를 공유하는 컴포넌트는 하나의 경계 안에 묶는 것이 자연스럽습니다.

**원칙 2: 사용자 인지 단위로 그룹화합니다.** 사용자가 하나의 의미 있는 단위로 인식하는 UI 블록은 함께 로딩되어야 합니다. 예를 들어, 상품 이미지와 가격은 함께 나타나야 하지 상품 이미지만 먼저 나타나고 가격이 따로 나타나면 오히려 사용자를 혼란스럽게 합니다.

**원칙 3: 중첩 경계로 우선순위를 표현합니다.** 가장 중요한 콘텐츠는 상위 수준에, 부가 정보는 하위 수준에 배치합니다.

```typescript
// app/product/[id]/page.tsx
// 좋은 예: 계층적 Suspense 경계

export default function ProductPage({ params }: { params: { id: string } }) {
  return (
    <main>
      {/* 레벨 1: 핵심 상품 정보 (최우선 로딩) */}
      <Suspense fallback={<ProductHeroSkeleton />}>
        <ProductHero id={params.id} />

        {/* 레벨 2: 상품 상세 내부의 부가 정보 */}
        <div className="product-details">
          <Suspense fallback={<ReviewSummarySkeleton />}>
            <ReviewSummary productId={params.id} />
          </Suspense>

          <Suspense fallback={<AvailabilitySkeleton />}>
            <StoreAvailability productId={params.id} />
          </Suspense>
        </div>
      </Suspense>

      {/* 레벨 1: 추천 상품 (낮은 우선순위) */}
      <Suspense fallback={<RecommendationsSkeleton />}>
        <Recommendations productId={params.id} />
      </Suspense>
    </main>
  );
}
```

이 구조에서 `ProductHero`가 가장 먼저 표시됩니다. 그 안의 `ReviewSummary`와 `StoreAvailability`는 상품 정보가 로딩된 후에 독립적으로 채워지며, `Recommendations`는 전체 구조와 무관하게 자체 타이밍으로 로딩됩니다.

### 안티패턴: 피해야 할 Suspense 경계 설계

```typescript
// ❌ 안티패턴 1: 모든 것을 하나의 경계로 묶기
// 가장 느린 컴포넌트가 모든 것을 블로킹함
export default function BadDashboard() {
  return (
    <Suspense fallback={<FullPageLoader />}>
      <UserProfile />     {/* 50ms */}
      <Notifications />   {/* 200ms */}
      <Analytics />        {/* 2000ms */}
    </Suspense>
  );
}

// ❌ 안티패턴 2: 과도한 세분화
// 사용자 경험이 "팝콘" 효과로 산만해짐
export default function BadProductCard() {
  return (
    <div className="product-card">
      <Suspense fallback={<span>...</span>}>
        <ProductImage />
      </Suspense>
      <Suspense fallback={<span>...</span>}>
        <ProductTitle />
      </Suspense>
      <Suspense fallback={<span>...</span>}>
        <ProductPrice />
      </Suspense>
      <Suspense fallback={<span>...</span>}>
        <ProductRating />
      </Suspense>
    </div>
  );
}
```

첫 번째 안티패턴에서는 50ms 만에 보여줄 수 있는 프로필을 2초나 기다려야 합니다. 두 번째에서는 상품 카드의 각 요소가 제각각 나타나면서 레이아웃이 불안정해지고 CLS(Cumulative Layout Shift) 점수가 악화됩니다.

## 병렬 데이터 페칭과 워터폴 제거

### 서버 컴포넌트의 워터폴 문제

RSC에서 가장 흔한 성능 병목은 **데이터 페칭 워터폴**입니다. 부모 컴포넌트가 데이터를 가져온 후에야 자식 컴포넌트가 렌더링을 시작하면, 각 데이터 요청이 직렬로 실행됩니다.

```typescript
// ❌ 워터폴 발생: 순차적 데이터 페칭
// app/dashboard/analytics.tsx

async function AnalyticsSection() {
  // 1단계: 사용자 설정 조회 (100ms)
  const settings = await fetchUserSettings();

  // 2단계: 설정 기반으로 차트 데이터 조회 (500ms)
  const chartData = await fetchChartData(settings.dateRange);

  // 3단계: 비교 데이터 조회 (300ms)
  const comparison = await fetchComparison(settings.dateRange);

  // 총 소요: 100 + 500 + 300 = 900ms
  return <Chart data={chartData} comparison={comparison} />;
}
```

### Promise.all과 병렬 페칭 패턴

의존성이 없는 데이터 요청은 반드시 병렬로 실행해야 합니다. 이것이 가장 간단하면서도 효과적인 최적화입니다.

```typescript
// ✅ 병렬 페칭: 독립적 요청을 동시 실행
// app/dashboard/analytics.tsx

async function AnalyticsSection() {
  // 1단계: 설정은 여전히 먼저 필요
  const settings = await fetchUserSettings(); // 100ms

  // 2단계: 설정 기반 요청들을 병렬 실행
  const [chartData, comparison, benchmarks] = await Promise.all([
    fetchChartData(settings.dateRange),    // 500ms
    fetchComparison(settings.dateRange),   // 300ms
    fetchBenchmarks(settings.industry),    // 400ms
  ]);

  // 총 소요: 100 + max(500, 300, 400) = 600ms (33% 개선)
  return (
    <Chart
      data={chartData}
      comparison={comparison}
      benchmarks={benchmarks}
    />
  );
}
```

### 고급 패턴: 프리페칭과 데이터 호이스팅

더 공격적인 최적화로, **데이터 요청을 시작하는 시점**을 컴포넌트 렌더링보다 앞당길 수 있습니다. Next.js에서는 `page.tsx`에서 Promise를 생성하고 자식 컴포넌트에 전달하는 패턴을 사용합니다.

```typescript
// app/dashboard/page.tsx
// 데이터 호이스팅 패턴: 페이지 수준에서 모든 요청을 동시에 시작

export default function DashboardPage() {
  // 렌더링 시작과 동시에 모든 데이터 요청 발사
  // await 하지 않으므로 즉시 Promise 반환
  const userPromise = fetchUser();
  const notificationsPromise = fetchNotifications();
  const analyticsPromise = fetchAnalytics();
  const recommendationsPromise = fetchRecommendations();

  return (
    <div className="dashboard">
      <Suspense fallback={<ProfileSkeleton />}>
        <UserProfile dataPromise={userPromise} />
      </Suspense>

      <Suspense fallback={<NotificationSkeleton />}>
        <NotificationList dataPromise={notificationsPromise} />
      </Suspense>

      <Suspense fallback={<AnalyticsSkeleton />}>
        <AnalyticsPanel dataPromise={analyticsPromise} />
      </Suspense>

      <Suspense fallback={<RecommendationSkeleton />}>
        <RecommendationPanel dataPromise={recommendationsPromise} />
      </Suspense>
    </div>
  );
}

// 자식 컴포넌트에서 Promise를 await
async function UserProfile({
  dataPromise,
}: {
  dataPromise: Promise<User>;
}) {
  const user = await dataPromise; // 이미 진행 중인 요청을 대기
  return (
    <div className="profile">
      <Avatar src={user.avatarUrl} />
      <h2>{user.name}</h2>
      <p>{user.role}</p>
    </div>
  );
}
```

이 패턴의 핵심은 **await를 최대한 늦추는 것**입니다. `page.tsx`에서 Promise를 생성하되 await하지 않고, 각 자식 컴포넌트가 필요한 시점에 await합니다. 모든 네트워크 요청이 즉시 병렬로 시작되므로, 총 로딩 시간은 가장 느린 단일 요청의 시간으로 수렴합니다.

## 정적 셸 패턴: 즉각적인 첫 화면

### 정적 셸이란 무엇인가

정적 셸(Static Shell) 패턴은 RSC 스트리밍의 가장 강력한 최적화 전략입니다. 페이지의 레이아웃, 네비게이션, 사이드바 같은 **데이터에 의존하지 않는 UI**를 즉시 전송하고, 동적 콘텐츠 영역만 Suspense 폴백으로 처리합니다.

이 패턴이 강력한 이유는 **First Contentful Paint(FCP)를 거의 0에 가깝게 만들기 때문**입니다. 사용자는 페이지 구조를 즉시 인식하고, 어디에 어떤 콘텐츠가 올지 예상할 수 있습니다. 이는 체감 성능을 극적으로 향상시킵니다.

```typescript
// app/layout.tsx
// 정적 셸 - 모든 페이지에서 즉시 렌더링

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="ko">
      <body>
        {/* 100% 정적 - 즉시 전송 */}
        <header className="global-header">
          <Logo />
          <MainNavigation />
          <Suspense fallback={<UserMenuSkeleton />}>
            <UserMenu /> {/* 인증 정보만 동적 */}
          </Suspense>
        </header>

        {/* 사이드바도 정적 */}
        <aside className="sidebar">
          <SidebarNavigation />
        </aside>

        {/* 메인 콘텐츠만 동적으로 스트리밍 */}
        <main className="content">{children}</main>

        {/* 푸터 정적 */}
        <footer className="global-footer">
          <FooterLinks />
        </footer>
      </body>
    </html>
  );
}
```

### CLS 방지를 위한 스켈레톤 설계

스트리밍에서 가장 주의할 점은 **Cumulative Layout Shift(CLS)**입니다. 폴백 UI와 실제 콘텐츠의 크기가 다르면 레이아웃이 밀리면서 사용자 경험이 크게 저하됩니다.

```typescript
// components/skeletons.tsx
// CLS 방지를 위한 정확한 크기의 스켈레톤

export function ProductCardSkeleton() {
  return (
    <div
      className="product-card"
      // 실제 ProductCard와 동일한 크기를 보장
      style={{ minHeight: '320px', width: '280px' }}
    >
      {/* 이미지 영역: 실제와 동일한 비율 */}
      <div
        className="skeleton-pulse"
        style={{ aspectRatio: '4/3', width: '100%' }}
      />
      {/* 텍스트 영역: 예상 줄 수에 맞춤 */}
      <div className="skeleton-text" style={{ height: '24px', width: '80%' }} />
      <div className="skeleton-text" style={{ height: '20px', width: '40%' }} />
      <div className="skeleton-text" style={{ height: '32px', width: '60%' }} />
    </div>
  );
}

// CSS: 스켈레톤 애니메이션
// 부드러운 펄스 효과로 로딩 상태를 시각적으로 표현
const skeletonStyles = `
  .skeleton-pulse {
    background: linear-gradient(
      90deg,
      hsl(0 0% 90%) 0%,
      hsl(0 0% 95%) 50%,
      hsl(0 0% 90%) 100%
    );
    background-size: 200% 100%;
    animation: skeleton-pulse 1.5s ease-in-out infinite;
    border-radius: 8px;
  }

  @keyframes skeleton-pulse {
    0% { background-position: 200% 0; }
    100% { background-position: -200% 0; }
  }
`;
```

> **중요:** 스켈레톤의 높이와 너비가 실제 콘텐츠와 정확히 일치해야 합니다. 가변 높이 콘텐츠에는 `min-height`를 설정하여 최소 크기를 보장하되, CSS Grid나 Flexbox의 `place-items`를 활용하여 콘텐츠가 커져도 자연스럽게 확장되도록 설계합니다.

## 프로덕션 성능 측정과 최적화

### Core Web Vitals 모니터링

RSC 스트리밍의 효과를 정량적으로 측정하려면 Core Web Vitals를 체계적으로 모니터링해야 합니다. 특히 **LCP(Largest Contentful Paint)**와 **TTFB(Time to First Byte)**가 가장 직접적인 영향을 받습니다.

```typescript
// lib/performance-monitor.ts
// 프로덕션 성능 측정 유틸리티

export function reportWebVitals() {
  if (typeof window === 'undefined') return;

  // LCP 측정: 스트리밍 효과를 가장 잘 보여주는 지표
  new PerformanceObserver((entryList) => {
    const entries = entryList.getEntries();
    const lastEntry = entries[entries.length - 1] as PerformanceEntry & {
      renderTime: number;
      loadTime: number;
    };

    const lcp = lastEntry.renderTime || lastEntry.loadTime;
    console.log(`LCP: ${lcp.toFixed(0)}ms`);

    // 분석 서비스로 전송
    sendToAnalytics({
      metric: 'LCP',
      value: lcp,
      page: window.location.pathname,
    });
  }).observe({ type: 'largest-contentful-paint', buffered: true });

  // TTFB 측정: 스트리밍 시작 시점
  new PerformanceObserver((entryList) => {
    const [navigation] = entryList.getEntriesByType(
      'navigation'
    ) as PerformanceNavigationTiming[];

    if (navigation) {
      const ttfb = navigation.responseStart - navigation.requestStart;
      console.log(`TTFB: ${ttfb.toFixed(0)}ms`);
      sendToAnalytics({ metric: 'TTFB', value: ttfb });
    }
  }).observe({ type: 'navigation', buffered: true });
}

function sendToAnalytics(data: {
  metric: string;
  value: number;
  page?: string;
}) {
  // Vercel Analytics, DataDog, 또는 커스텀 엔드포인트로 전송
  if (navigator.sendBeacon) {
    navigator.sendBeacon('/api/analytics', JSON.stringify(data));
  }
}
```

### 실전 벤치마크: 전통적 SSR vs RSC 스트리밍

실제 프로덕션 대시보드 애플리케이션에서 측정한 벤치마크 결과입니다. 테스트 환경은 4개의 독립 API 엔드포인트(응답 시간: 50ms, 200ms, 800ms, 1500ms)를 호출하는 대시보드 페이지입니다.

| 지표 | 전통적 SSR | RSC 스트리밍 | 개선율 |
|------|-----------|-------------|--------|
| TTFB | 1,580ms | 45ms | **97% ↓** |
| FCP | 1,620ms | 85ms | **95% ↓** |
| LCP | 1,650ms | 220ms | **87% ↓** |
| TTI | 2,100ms | 350ms | **83% ↓** |
| CLS | 0.00 | 0.02 | 미미한 차이 |

TTFB가 1,580ms에서 45ms로 극적으로 감소한 것은, 스트리밍이 정적 셸을 즉시 전송하기 때문입니다. LCP 역시 가장 빠른 의미 있는 콘텐츠(사용자 프로필, 200ms 응답)가 도착한 직후 측정되므로 크게 개선됩니다.

## 고급 패턴: 조건부 스트리밍과 에러 경계

### 에러 처리와 Suspense의 조합

프로덕션에서는 데이터 페칭이 실패할 수 있으므로, Suspense 경계마다 에러 처리를 반드시 포함해야 합니다. React의 Error Boundary를 Suspense와 조합하면, 한 섹션의 실패가 전체 페이지에 영향을 미치지 않습니다.

```typescript
// components/resilient-section.tsx
'use client';

import { Component, Suspense, type ReactNode } from 'react';

interface ErrorBoundaryProps {
  fallback: ReactNode;
  children: ReactNode;
}

interface ErrorBoundaryState {
  hasError: boolean;
  error: Error | null;
}

class ErrorBoundary extends Component<ErrorBoundaryProps, ErrorBoundaryState> {
  state: ErrorBoundaryState = { hasError: false, error: null };

  static getDerivedStateFromError(error: Error) {
    return { hasError: true, error };
  }

  render() {
    if (this.state.hasError) {
      return this.props.fallback;
    }
    return this.props.children;
  }
}

// 조합 컴포넌트: Error Boundary + Suspense
export function ResilientSection({
  children,
  loadingFallback,
  errorFallback,
}: {
  children: ReactNode;
  loadingFallback: ReactNode;
  errorFallback: ReactNode;
}) {
  return (
    <ErrorBoundary fallback={errorFallback}>
      <Suspense fallback={loadingFallback}>
        {children}
      </Suspense>
    </ErrorBoundary>
  );
}
```

```typescript
// 사용 예: 각 섹션이 독립적으로 실패하고 복구
// app/dashboard/page.tsx

import { ResilientSection } from '@/components/resilient-section';

export default function Dashboard() {
  const analyticsPromise = fetchAnalytics();
  const notificationsPromise = fetchNotifications();

  return (
    <div className="dashboard">
      <ResilientSection
        loadingFallback={<AnalyticsSkeleton />}
        errorFallback={
          <div className="error-card">
            <p>분석 데이터를 불러올 수 없습니다.</p>
            <RefreshButton section="analytics" />
          </div>
        }
      >
        <AnalyticsPanel dataPromise={analyticsPromise} />
      </ResilientSection>

      <ResilientSection
        loadingFallback={<NotificationSkeleton />}
        errorFallback={
          <div className="error-card">
            <p>알림을 불러올 수 없습니다.</p>
            <RefreshButton section="notifications" />
          </div>
        }
      >
        <NotificationList dataPromise={notificationsPromise} />
      </ResilientSection>
    </div>
  );
}
```

이 패턴의 장점은 **장애 격리**입니다. 분석 API가 다운되어도 알림은 정상적으로 표시됩니다. 각 섹션은 독립적인 에러 상태를 가지며, 사용자는 실패한 섹션만 선택적으로 새로고침할 수 있습니다.

### 캐싱 전략과 스트리밍의 조화

Next.js의 `unstable_cache`(또는 React의 `cache`)를 활용하면 데이터 페칭 결과를 캐시하면서도 스트리밍의 이점을 유지할 수 있습니다.

```typescript
// lib/data.ts
import { unstable_cache } from 'next/cache';

// 캐시된 데이터 페칭: 재검증 주기 설정
export const getCachedAnalytics = unstable_cache(
  async (userId: string, dateRange: string) => {
    const response = await fetch(
      `${API_BASE}/analytics?user=${userId}&range=${dateRange}`
    );
    return response.json();
  },
  ['analytics'], // 캐시 키
  {
    revalidate: 300, // 5분마다 재검증
    tags: ['analytics'], // 수동 무효화를 위한 태그
  }
);

// 캐시 미스 시에도 스트리밍은 정상 작동
// - 캐시 히트: Suspense가 즉시 해제 (거의 0ms)
// - 캐시 미스: 기존처럼 폴백 표시 후 데이터 도착 시 교체
```

> **프로 팁:** 자주 바뀌지 않는 데이터(사용자 프로필, 설정)는 긴 재검증 주기로 캐시하고, 실시간성이 중요한 데이터(알림, 메시지)는 캐시 없이 스트리밍합니다. 이렇게 하면 대부분의 Suspense 경계가 즉시 해제되어 사용자 경험이 크게 향상됩니다.

## loading.tsx와 Suspense의 관계

Next.js App Router에서 `loading.tsx`는 사실 해당 라우트 세그먼트를 자동으로 Suspense 경계로 감싸는 편의 기능입니다. 그러나 세밀한 제어가 필요할 때는 직접 Suspense를 사용하는 것이 좋습니다.

```typescript
// app/dashboard/loading.tsx
// 이 파일은 Next.js가 자동으로 아래처럼 변환합니다:
// <Suspense fallback={<Loading />}>
//   <DashboardPage />
// </Suspense>

export default function Loading() {
  return (
    <div className="dashboard-loading">
      <div className="skeleton-grid">
        <ProfileSkeleton />
        <NotificationSkeleton />
        <AnalyticsSkeleton />
      </div>
    </div>
  );
}
```

`loading.tsx`를 사용하면 전체 페이지 수준의 로딩 상태를 간편하게 정의할 수 있지만, 페이지 내부의 각 섹션을 독립적으로 스트리밍하려면 컴포넌트 수준의 Suspense 경계가 필수적입니다. 실무에서는 두 가지를 조합하여 사용합니다. `loading.tsx`로 라우트 전환 시 전체 폴백을 보여주고, 페이지 내부에서는 세밀한 Suspense 경계로 점진적 로딩을 구현합니다.

## 결론: 스트리밍 우선 아키텍처로의 전환

RSC 스트리밍은 단순한 성능 최적화 기법이 아닙니다. 이것은 "사용자에게 무엇을, 언제 보여줄 것인가"에 대한 근본적인 사고 방식의 전환입니다. 전통적 SSR이 "모든 것이 준비되면 한 번에 보여주겠다"는 철학이라면, RSC 스트리밍은 "준비된 것부터 즉시 보여주고, 나머지는 점진적으로 채우겠다"는 철학입니다.

이 글에서 다룬 핵심 패턴을 정리하면 다음과 같습니다. **정적 셸 패턴**으로 즉각적인 첫 화면을 보장하고, **계층적 Suspense 경계**로 콘텐츠 우선순위를 표현하며, **데이터 호이스팅**으로 워터폴을 제거하고, **ResilientSection 패턴**으로 장애를 격리합니다. 이 네 가지 패턴을 조합하면 TTFB 97%, LCP 87% 개선이라는 극적인 결과를 달성할 수 있습니다.

중요한 것은 이 모든 패턴이 **점진적으로 도입 가능**하다는 점입니다. 기존 Next.js 프로젝트에서 가장 느린 페이지 하나를 골라 Suspense 경계를 추가하는 것만으로도 즉각적인 개선을 체감할 수 있습니다. 완벽한 아키텍처를 한 번에 구축하려 하지 말고, 사용자가 가장 많이 방문하는 페이지부터 점진적으로 스트리밍 우선 아키텍처로 전환해 나가시기 바랍니다.
