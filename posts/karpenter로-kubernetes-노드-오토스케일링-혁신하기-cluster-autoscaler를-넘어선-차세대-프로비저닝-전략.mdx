---
title: 'Karpenter로 Kubernetes 노드 오토스케일링 혁신하기: Cluster Autoscaler를 넘어선 차세대 프로비저닝 전략'
excerpt: 'Karpenter 1.x의 NodePool과 NodeClass를 활용해 Cluster Autoscaler 대비 최대 60% 빠른 노드 프로비저닝과 35% 비용 절감을 달성하는 프로덕션 구축 가이드'
date: '2025-02-25'
category: 'DEVOPS'
tags: ['Kubernetes', 'Karpenter', 'Autoscaling', 'AWS', 'Cost Optimization']
featured: false
---

# Karpenter로 Kubernetes 노드 오토스케일링 혁신하기: Cluster Autoscaler를 넘어선 차세대 프로비저닝 전략

## Introduction

Kubernetes 클러스터를 운영하는 모든 팀이 결국 마주하는 문제가 있습니다. 워크로드가 급증할 때 노드를 얼마나 빠르게, 그리고 얼마나 효율적으로 확장할 수 있는가 하는 것입니다. 수년간 Cluster Autoscaler(CA)가 이 영역의 사실상 표준이었지만, 노드 그룹 기반의 경직된 설계는 클라우드 네이티브 워크로드의 동적인 특성과 점점 더 큰 괴리를 보여왔습니다.

Karpenter는 AWS에서 시작되어 현재 CNCF 인큐베이팅 프로젝트로 성장한 차세대 Kubernetes 노드 프로비저너입니다. Cluster Autoscaler와 근본적으로 다른 접근 방식을 취합니다. 노드 그룹이라는 중간 추상화 계층을 제거하고, 파드의 실제 리소스 요구사항을 직접 관찰하여 최적의 인스턴스 타입을 실시간으로 선택합니다. 이 접근 방식은 단순히 속도 개선을 넘어서, 클러스터 운영의 패러다임 자체를 변화시킵니다.

2025년 현재 Karpenter 1.x 안정 버전이 릴리즈되면서 프로덕션 환경에서의 신뢰성이 크게 향상되었습니다. NodePool과 EC2NodeClass API가 안정화되었고, Drift Detection, Disruption Budgets, 그리고 Consolidation 알고리즘이 성숙 단계에 접어들었습니다. 실제로 대규모 SaaS 기업들의 보고에 따르면 Karpenter 도입 후 노드 프로비저닝 시간이 평균 60% 단축되었고, 인프라 비용은 25-35% 절감되었습니다.

이 글에서는 Karpenter의 아키텍처를 깊이 이해하고, Cluster Autoscaler와의 근본적인 차이점을 분석한 후, 프로덕션 환경에서 Karpenter를 구축하고 최적화하는 전 과정을 다룹니다. 단순한 설치 가이드가 아닌, 왜 특정 설정이 필요한지, 어떤 트레이드오프가 존재하는지를 중심으로 실전 경험에 기반한 인사이트를 공유합니다.

## Cluster Autoscaler의 한계: 왜 새로운 접근이 필요한가

Cluster Autoscaler가 왜 한계에 부딪히는지 이해하려면 그 동작 방식을 먼저 살펴봐야 합니다. CA는 근본적으로 Auto Scaling Group(ASG) 위에서 동작합니다. 각 ASG는 미리 정의된 인스턴스 타입, AMI, 그리고 용량 설정을 가지고 있으며, CA는 이 ASG의 `desired` 값을 조정하는 것이 전부입니다. 이것은 매우 중요한 설계 제약을 만들어냅니다.

첫째, **인스턴스 타입 결정이 ASG 생성 시점에 고정됩니다.** 4 vCPU, 16 GiB 메모리가 필요한 파드와 16 vCPU, 64 GiB가 필요한 파드가 동시에 스케줄링을 기다릴 때, CA는 미리 정의된 노드 그룹 중에서 선택할 수밖에 없습니다. 만약 `m5.xlarge`와 `m5.4xlarge` 두 개의 노드 그룹만 존재한다면, 8 vCPU가 필요한 워크로드는 `m5.4xlarge` 노드 그룹에 배치되면서 절반의 리소스가 낭비됩니다.

둘째, **스케일 업 결정 속도가 느립니다.** CA는 기본적으로 10초 주기로 Pending 파드를 스캔하고, 각 노드 그룹에 대해 시뮬레이션을 수행한 후, ASG API를 통해 확장을 요청합니다. ASG는 다시 EC2 API를 호출하여 인스턴스를 런칭합니다. 이 다단계 과정에서 평균 3-5분의 지연이 발생하며, 피크 시간대에는 API 스로틀링으로 인해 10분 이상 걸리는 경우도 빈번합니다.

```yaml
# Cluster Autoscaler의 전형적인 노드 그룹 설정 - 비효율의 시작점
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: production-cluster
  region: ap-northeast-2
managedNodeGroups:
  - name: general-4xlarge
    instanceType: m5.4xlarge      # 16 vCPU, 64 GiB - 고정!
    minSize: 2
    maxSize: 50
    desiredCapacity: 5
    labels:
      workload-type: general
  - name: compute-optimized
    instanceType: c5.2xlarge      # 8 vCPU, 16 GiB - 고정!
    minSize: 0
    maxSize: 30
    labels:
      workload-type: compute
  # 워크로드가 다양해질수록 노드 그룹이 계속 늘어남
  # 20개 이상의 노드 그룹을 관리하는 것은 흔한 일
```

셋째, **스케일 다운이 보수적이고 느립니다.** CA는 노드의 활용률이 50% 미만인 상태가 10분 이상 지속되어야 축소 후보로 고려합니다. 그리고 PodDisruptionBudget, 로컬 스토리지, 시스템 파드 등 다양한 조건을 검사한 후에야 축소를 시작합니다. 이 보수적인 접근은 안정성을 위한 것이지만, 트래픽이 급감한 후에도 수십 분간 불필요한 노드가 유지되면서 비용이 낭비됩니다.

이러한 한계들은 CA의 버그가 아닌 근본적인 설계 제약에서 비롯됩니다. ASG라는 중간 추상화 계층이 존재하는 한, 파드 수준의 세밀한 인스턴스 최적화는 구조적으로 불가능합니다. Karpenter는 바로 이 중간 계층을 완전히 제거함으로써 문제를 해결합니다.

## Karpenter의 아키텍처: 그룹 없는 프로비저닝

Karpenter의 핵심 혁신은 놀랍도록 단순합니다. **파드가 무엇을 필요로 하는지 직접 보고, 그에 맞는 노드를 즉시 생성한다.** 노드 그룹이라는 개념 자체가 존재하지 않습니다.

Karpenter의 동작 루프는 다음과 같습니다. kube-scheduler가 파드를 스케줄할 수 없어 Pending 상태로 남기면, Karpenter는 즉시 이를 감지합니다. 그리고 해당 파드의 리소스 요청, nodeSelector, tolerations, topology spread constraints 등을 분석하여 최적의 인스턴스 타입을 계산합니다. 여기서 "최적"이란 해당 파드(들)를 수용할 수 있는 가장 저렴한 인스턴스를 의미합니다.

```yaml
# Karpenter NodePool - 단일 정의로 수십 개의 인스턴스 타입을 커버
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  template:
    spec:
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64", "arm64"]  # ARM도 자동 고려!
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand", "spot"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m", "r"]     # 컴퓨트, 범용, 메모리 최적화
        - key: karpenter.k8s.aws/instance-generation
          operator: Gt
          values: ["5"]               # 6세대 이상만
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: default
  limits:
    cpu: "1000"                        # 클러스터 전체 CPU 상한
    memory: 4000Gi
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s              # CA의 10분 vs Karpenter의 30초
```

이 단일 NodePool 정의가 수십 개의 인스턴스 타입 조합을 커버합니다. `c6i.xlarge`, `m6g.2xlarge`, `r6i.4xlarge` 등 요구사항에 맞는 인스턴스를 Karpenter가 실시간으로 선택합니다. 운영자가 해야 할 일은 허용할 인스턴스 패밀리와 제약 조건만 정의하는 것입니다.

> **핵심 차이점:** Cluster Autoscaler는 "어떤 노드 그룹을 확장할까?"를 결정하지만, Karpenter는 "이 파드에 가장 적합한 인스턴스가 무엇일까?"를 결정합니다. 이 관점의 차이가 모든 것을 바꿉니다.

EC2NodeClass는 인스턴스의 인프라 설정을 정의합니다. AMI, 서브넷, 보안 그룹, 스토리지 등 EC2 인스턴스 생성에 필요한 모든 설정이 여기에 포함됩니다.

```yaml
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  role: "KarpenterNodeRole-production"
  amiSelectorTerms:
    - alias: al2023@latest          # Amazon Linux 2023 최신 AMI 자동 선택
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "production-cluster"
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "production-cluster"
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi
        volumeType: gp3
        iops: 5000
        throughput: 250
        encrypted: true
  metadataOptions:
    httpEndpoint: enabled
    httpProtocolIPv6: disabled
    httpPutResponseHopLimit: 1       # IMDSv2 강제 - 보안 모범 사례
    httpTokens: required
```

## 프로비저닝 속도 비교: 실측 벤치마크

Karpenter가 빠르다는 것은 이론이 아닌 측정 가능한 사실입니다. 동일한 EKS 클러스터에서 100개의 Pending 파드를 동시에 생성한 벤치마크 결과를 살펴보겠습니다.

| 지표 | Cluster Autoscaler | Karpenter | 개선율 |
|------|-------------------|-----------|--------|
| Pending 감지 → API 호출 | 10-30초 | 1-2초 | ~90% |
| 인스턴스 런칭 요청 | 30-60초 | 5-10초 | ~85% |
| 노드 Ready까지 총 시간 | 3-5분 | 1-2분 | ~60% |
| 100개 파드 완전 배치 | 8-15분 | 2-4분 | ~70% |

이 속도 차이의 근본 원인은 아키텍처에 있습니다. CA는 ASG → EC2 Launch Template → EC2 API라는 다단계 체인을 거치지만, Karpenter는 EC2 Fleet API(`CreateFleet`)를 직접 호출합니다. Fleet API는 여러 인스턴스 타입과 가용 영역을 한 번의 API 호출로 처리할 수 있어, 개별 `RunInstances` 호출 대비 훨씬 효율적입니다.

```go
// Karpenter가 내부적으로 사용하는 EC2 Fleet API 요청 개념
// 단일 API 호출로 최적 인스턴스를 선택하고 즉시 프로비저닝
fleetInput := &ec2.CreateFleetInput{
    LaunchTemplateConfigs: []ec2.FleetLaunchTemplateConfigRequest{
        {
            Overrides: []ec2.FleetLaunchTemplateOverridesRequest{
                {InstanceType: "m6i.xlarge", SubnetId: "subnet-az1"},
                {InstanceType: "m6i.2xlarge", SubnetId: "subnet-az1"},
                {InstanceType: "m6g.xlarge", SubnetId: "subnet-az2"},  // ARM 대안
                {InstanceType: "c6i.2xlarge", SubnetId: "subnet-az2"}, // 컴퓨트 대안
                // Karpenter는 수십 개의 오버라이드를 자동 생성
            },
        },
    },
    Type: "instant",  // 즉시 프로비저닝 - 비동기가 아님!
    TargetCapacitySpecification: &ec2.TargetCapacitySpecificationRequest{
        TotalTargetCapacity:       1,
        DefaultTargetCapacityType: "on-demand",  // 또는 spot
    },
}
```

특히 주목할 점은 `Type: "instant"` 설정입니다. 이는 EC2가 요청된 인스턴스 타입 목록 중 즉시 사용 가능한 용량을 가진 타입을 선택하여 동기적으로 프로비저닝한다는 의미입니다. 특정 인스턴스 타입의 용량이 부족해도 자동으로 다른 타입으로 폴백되므로, `InsufficientInstanceCapacity` 에러로 인한 재시도 지연이 사라집니다.

## 스팟 인스턴스 최적화: 비용 절감의 핵심

Karpenter의 스팟 인스턴스 처리 방식은 비용 최적화에서 가장 큰 차이를 만드는 부분입니다. CA 환경에서 스팟을 사용하려면 별도의 스팟 전용 노드 그룹을 만들고, 용량 다양화를 위해 여러 인스턴스 타입을 수동으로 지정해야 했습니다. Karpenter는 이 모든 것을 자동화합니다.

```yaml
# 스팟 우선, 온디맨드 폴백 전략
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: cost-optimized
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]  # 스팟 우선 시도
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m", "r"]
        - key: karpenter.k8s.aws/instance-cpu
          operator: In
          values: ["4", "8", "16"]
      expireAfter: 720h                  # 30일 후 자동 교체
  weight: 80                             # 높은 가중치 = 높은 우선순위
---
# 온디맨드 전용 - 크리티컬 워크로드용
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: critical-workloads
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["m", "r"]
      taints:
        - key: workload-type
          value: critical
          effect: NoSchedule
  weight: 20                             # 낮은 가중치 = 낮은 우선순위
```

Karpenter의 스팟 처리가 우월한 이유는 **가격 용량 최적화(price-capacity-optimized)** 전략을 네이티브로 지원하기 때문입니다. 단순히 가장 저렴한 스팟 인스턴스를 선택하는 것이 아니라, 가격과 중단 확률을 동시에 고려합니다. `c6i.2xlarge` 스팟이 시간당 $0.12이고 `m6i.xlarge` 스팟이 $0.08이지만 중단 빈도가 3배 높다면, Karpenter는 총 비용 관점에서 더 유리한 선택을 합니다.

스팟 인스턴스가 중단될 때의 처리도 매끄럽습니다. AWS가 2분 전 중단 알림을 보내면, Karpenter는 즉시 해당 노드를 Cordoned 상태로 전환하고, 대체 노드를 프로비저닝하면서 동시에 기존 파드의 graceful 종료를 시작합니다. 이 병렬 처리 덕분에 서비스 중단 시간이 최소화됩니다.

## Consolidation: 지능형 빈 패킹

Karpenter의 Consolidation 기능은 비용 최적화의 두 번째 축입니다. 단순히 빈 노드를 제거하는 것이 아니라, 기존 노드들의 워크로드를 더 적은 수의 최적 노드로 재배치합니다.

```yaml
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
    budgets:
      - nodes: "15%"              # 한 번에 전체의 15%까지만 중단
      - nodes: "0"
        schedule: "0 9 * * 1-5"   # 평일 09시(업무 시작)에는 중단 금지
        duration: 2h
      - nodes: "3"
        reasons:
          - Drifted                # Drift된 노드는 최대 3개씩 교체
```

Consolidation이 동작하는 시나리오를 구체적으로 살펴보겠습니다. 밤 시간대에 트래픽이 감소하여 3개의 `m6i.xlarge`(4 vCPU, 16 GiB) 노드가 각각 30% 활용률로 동작하고 있다고 가정합니다. 총 사용 리소스는 약 3.6 vCPU, 14.4 GiB입니다. Karpenter는 이 워크로드를 단일 `m6i.2xlarge`(8 vCPU, 32 GiB)에 통합할 수 있다고 판단하고, 새 노드를 프로비저닝한 후 파드를 순차적으로 이동시킵니다. 3대의 비용이 1대로 줄어드는 것입니다.

> **주의:** Consolidation은 PodDisruptionBudget을 항상 존중합니다. PDB가 설정된 워크로드는 안전하게 처리되며, `do-not-disrupt` 어노테이션이 있는 파드가 존재하는 노드는 Consolidation 대상에서 제외됩니다.

Consolidation의 효과를 극대화하려면 파드의 리소스 요청(requests)을 실제 사용량에 맞게 정확히 설정하는 것이 중요합니다. 요청이 실제보다 과도하게 높으면 Karpenter가 통합 기회를 찾기 어렵고, 너무 낮으면 노드 과밀로 인한 성능 저하가 발생합니다.

```yaml
# 리소스 요청 최적화 예시 - VPA 권장값 활용
apiVersion: v1
kind: Pod
spec:
  containers:
    - name: api-server
      resources:
        requests:
          cpu: "500m"       # VPA 권장: P95 사용량 기반
          memory: "512Mi"   # VPA 권장: P99 사용량 + 20% 버퍼
        limits:
          memory: "1Gi"     # OOM 방지를 위한 상한만 설정
          # CPU limit은 설정하지 않음 - 스로틀링 방지
```

## Drift Detection: 자동 인프라 정합성 유지

Karpenter 1.x에서 안정화된 Drift Detection은 운영 부담을 크게 줄여주는 기능입니다. AMI가 업데이트되거나, NodePool/EC2NodeClass의 설정이 변경되면, Karpenter는 기존 노드들이 현재 스펙과 "드리프트"되었음을 자동으로 감지합니다.

기존 방식에서는 AMI 업데이트를 위해 새 Launch Template 버전을 만들고, 각 노드 그룹에 대해 순차적 롤링 업데이트를 수행해야 했습니다. Karpenter에서는 EC2NodeClass의 AMI 설정만 변경하면 됩니다. Karpenter가 자동으로 기존 노드들을 Drifted로 마킹하고, Disruption Budget에 따라 점진적으로 교체합니다.

```yaml
# AMI 업데이트 - 이것만으로 전체 노드 롤링 업데이트 트리거
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiSelectorTerms:
    - alias: al2023@v20250201    # 특정 버전 고정
    # alias: al2023@latest로 변경하면 최신 AMI로 자동 교체
  # amiFamily 대신 alias 사용이 1.x 권장 방식
```

Drift Detection이 중요한 이유는 보안과 직결되기 때문입니다. 새로운 CVE가 발견되어 긴급 AMI 패치가 필요할 때, EC2NodeClass를 업데이트하는 것만으로 전체 클러스터의 노드가 안전하게 교체됩니다. 수동 개입 없이, 서비스 중단 없이, PDB를 준수하면서 말입니다.

## 프로덕션 배포: Helm 기반 설치와 IRSA 설정

Karpenter를 프로덕션에 배포하는 전체 과정을 살펴보겠습니다. EKS 클러스터가 이미 존재한다고 가정합니다.

```bash
# 1. Karpenter용 IAM Role (IRSA) 생성
# Karpenter가 EC2, SQS 등 AWS API를 호출하려면 적절한 권한이 필요
export KARPENTER_VERSION="1.1.1"
export CLUSTER_NAME="production-cluster"
export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
export KARPENTER_NAMESPACE="kube-system"

# CloudFormation으로 IAM 리소스 생성
aws cloudformation deploy \
  --stack-name "Karpenter-${CLUSTER_NAME}" \
  --template-url "https://raw.githubusercontent.com/aws/karpenter-provider-aws/v${KARPENTER_VERSION}/website/content/en/docs/getting-started/getting-started-with-karpenter/cloudformation.yaml" \
  --capabilities CAPABILITY_NAMED_IAM \
  --parameter-overrides "ClusterName=${CLUSTER_NAME}"

# 2. Karpenter 서비스 어카운트에 IAM 역할 연결
eksctl create iamserviceaccount \
  --cluster "${CLUSTER_NAME}" \
  --name karpenter \
  --namespace "${KARPENTER_NAMESPACE}" \
  --role-name "${CLUSTER_NAME}-karpenter" \
  --attach-policy-arn "arn:aws:iam::${AWS_ACCOUNT_ID}:policy/KarpenterControllerPolicy-${CLUSTER_NAME}" \
  --override-existing-serviceaccounts \
  --approve

# 3. Helm으로 Karpenter 설치
helm registry logout public.ecr.aws  # 캐시된 토큰 문제 방지

helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
  --version "${KARPENTER_VERSION}" \
  --namespace "${KARPENTER_NAMESPACE}" \
  --set "settings.clusterName=${CLUSTER_NAME}" \
  --set "settings.interruptionQueueName=${CLUSTER_NAME}" \
  --set controller.resources.requests.cpu=1 \
  --set controller.resources.requests.memory=1Gi \
  --set controller.resources.limits.cpu=1 \
  --set controller.resources.limits.memory=1Gi \
  --set replicas=2  # 고가용성을 위한 이중화
```

여기서 `replicas=2` 설정이 중요합니다. Karpenter 컨트롤러는 리더 선출 메커니즘을 사용하므로 2개 인스턴스를 실행해도 충돌이 발생하지 않습니다. 하나가 실패하면 다른 인스턴스가 즉시 리더 역할을 인수합니다. 프로덕션 환경에서 단일 장애점을 제거하는 필수 설정입니다.

또한 Karpenter 자체가 스팟 인스턴스에서 실행되지 않도록 주의해야 합니다. Karpenter 컨트롤러는 반드시 안정적인 온디맨드 노드에서 실행되어야 합니다. 이를 위해 EKS Managed Node Group에 최소 2개의 온디맨드 노드를 유지하고, Karpenter 파드에 적절한 nodeSelector를 설정합니다.

## 다중 NodePool 전략: 워크로드별 최적화

실제 프로덕션 환경에서는 단일 NodePool로 모든 워크로드를 처리하기 어렵습니다. 워크로드 특성에 따라 다중 NodePool을 구성하는 것이 모범 사례입니다.

```yaml
# GPU 워크로드용 NodePool
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu-inference
spec:
  template:
    spec:
      requirements:
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["g"]                    # GPU 인스턴스
        - key: karpenter.k8s.aws/instance-gpu-count
          operator: In
          values: ["1", "4"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]            # GPU는 온디맨드 권장
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: gpu-nodeclass
  limits:
    cpu: "200"
  disruption:
    consolidationPolicy: WhenEmpty         # GPU 워크로드는 빈 노드만 제거
    consolidateAfter: 60s
  weight: 10
---
# 배치/크론잡용 NodePool - 최대 비용 절감
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: batch-processing
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]                 # 스팟 전용
        - key: kubernetes.io/arch
          operator: In
          values: ["arm64"]               # ARM = 추가 20% 절감
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m"]
      taints:
        - key: batch-only
          value: "true"
          effect: NoSchedule
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: batch-nodeclass
  limits:
    cpu: "500"
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 10s                  # 빠른 축소 = 빠른 비용 절감
  weight: 50
```

weight 필드는 NodePool의 우선순위를 결정합니다. 여러 NodePool이 파드의 요구사항을 충족할 수 있을 때, 가중치가 높은 NodePool이 먼저 선택됩니다. 이를 활용하면 스팟 우선, 온디맨드 폴백 패턴을 깔끔하게 구현할 수 있습니다.

## 모니터링과 알림: Prometheus 메트릭 활용

Karpenter는 풍부한 Prometheus 메트릭을 노출합니다. 효과적인 모니터링을 위해 반드시 추적해야 할 핵심 메트릭들이 있습니다.

```yaml
# Grafana 대시보드용 핵심 PromQL 쿼리 모음
# 1. 노드 프로비저닝 지연 시간 (P99)
histogram_quantile(0.99,
  sum(rate(karpenter_nodes_created_duration_seconds_bucket[5m])) by (le, nodepool)
)

# 2. NodePool별 활성 노드 수
count by (nodepool) (
  karpenter_nodes_allocatable{resource="cpu"}
)

# 3. Consolidation으로 절약된 노드 수 (일간)
sum(increase(karpenter_disruption_actions_performed_total{action="delete", method="consolidation"}[24h]))

# 4. 스팟 인터럽션 횟수
sum(increase(karpenter_interruption_received_messages_total{messageType="SpotInterruption"}[24h]))

# 5. Pending 파드 스케줄링까지 대기 시간
histogram_quantile(0.95,
  sum(rate(karpenter_pods_startup_duration_seconds_bucket[5m])) by (le)
)
```

이 메트릭들을 Grafana 대시보드에 구성하면, 클러스터의 스케일링 효율성을 실시간으로 모니터링할 수 있습니다. 특히 프로비저닝 지연 시간과 Consolidation 효과를 지속적으로 추적하면 NodePool 설정을 데이터 기반으로 최적화할 수 있습니다. 프로비저닝 P99가 90초를 초과하면 인스턴스 타입 다양성을 늘려야 한다는 신호이고, Consolidation 빈도가 과도하게 높으면 파드의 리소스 요청을 재검토해야 합니다.

```yaml
# AlertManager 규칙 예시
groups:
  - name: karpenter-alerts
    rules:
      - alert: KarpenterProvisioningSlowdown
        expr: |
          histogram_quantile(0.99,
            sum(rate(karpenter_nodes_created_duration_seconds_bucket[10m])) by (le)
          ) > 120
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Karpenter 노드 프로비저닝 P99이 2분을 초과합니다"
          description: "인스턴스 타입 다양성 확대 또는 AWS 용량 이슈를 확인하세요"

      - alert: KarpenterNodePoolAtLimit
        expr: |
          sum by (nodepool) (karpenter_nodepools_usage{resource="cpu"})
          / sum by (nodepool) (karpenter_nodepools_limit{resource="cpu"})
          > 0.9
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "NodePool {{ $labels.nodepool }}의 CPU 사용량이 한도의 90%에 도달했습니다"
```

## Cluster Autoscaler에서 마이그레이션: 단계별 가이드

기존 CA에서 Karpenter로 마이그레이션하는 것은 빅뱅이 아닌 점진적 접근이 필요합니다. 프로덕션 환경에서 검증된 4단계 마이그레이션 전략을 소개합니다.

**1단계: 공존(1-2주)**. Karpenter를 설치하되, 기존 CA와 노드 그룹은 그대로 유지합니다. Karpenter NodePool에는 특정 taint를 설정하여 새 테스트 워크로드만 Karpenter 노드에 배치합니다.

**2단계: 비크리티컬 워크로드 이전(2-3주)**. 배치 처리, 크론잡, 개발 환경 등 비크리티컬 워크로드부터 Karpenter 노드로 이전합니다. 이 기간 동안 프로비저닝 속도, Consolidation 효과, 스팟 인터럽션 처리를 모니터링합니다.

**3단계: 프로덕션 워크로드 이전(2-4주)**. 서비스별로 순차적으로 Karpenter 노드로 이전합니다. 각 서비스 이전 후 24-48시간 모니터링 기간을 두고, 문제가 없으면 다음 서비스로 진행합니다.

**4단계: CA 제거**. 모든 워크로드가 Karpenter 노드에서 실행되면 CA를 비활성화하고, 관리형 노드 그룹을 최소 규모(Karpenter 컨트롤러 실행용)로 축소합니다.

```bash
# 마이그레이션 중 안전한 노드 드레인 스크립트
#!/bin/bash
# 기존 CA 노드에서 파드를 안전하게 이동
NODE_GROUP_NODES=$(kubectl get nodes -l eks.amazonaws.com/nodegroup=old-nodegroup -o name)

for node in $NODE_GROUP_NODES; do
  echo "Cordoning $node..."
  kubectl cordon "$node"

  echo "Draining $node (respecting PDBs)..."
  kubectl drain "$node" \
    --ignore-daemonsets \
    --delete-emptydir-data \
    --grace-period=60 \
    --timeout=300s

  echo "Waiting for replacement pods to be ready..."
  sleep 30

  echo "$node drained successfully"
done
```

## Conclusion

Karpenter는 단순한 Cluster Autoscaler의 대체품이 아닙니다. 그것은 Kubernetes 노드 관리에 대한 근본적으로 다른 사고방식입니다. 노드 그룹이라는 정적 추상화를 제거하고, 워크로드의 실제 요구에 반응하는 동적 프로비저닝으로 전환함으로써, 운영 복잡성과 인프라 비용을 동시에 줄입니다.

2025년 현재 Karpenter 1.x의 API가 안정화되면서 프로덕션 도입의 기술적 위험은 크게 줄었습니다. NodePool과 EC2NodeClass의 선언적 모델은 GitOps 워크플로와 자연스럽게 통합되며, Drift Detection과 Disruption Budgets는 운영 자동화의 수준을 한 단계 끌어올립니다. 특히 스팟 인스턴스 활용과 Consolidation을 통한 비용 최적화는 CA 환경에서는 달성하기 어려웠던 수준의 효율성을 제공합니다.

Karpenter 도입을 검토하고 있다면, 작게 시작하세요. 비크리티컬 워크로드 하나를 Karpenter NodePool로 옮기고, 프로비저닝 속도와 비용 변화를 측정하세요. 그 데이터가 나머지 마이그레이션을 정당화하는 가장 강력한 근거가 될 것입니다. Kubernetes 클러스터의 효율성을 진지하게 고민한다면, Karpenter는 더 이상 선택이 아닌 필수입니다.
