---
title: 'DuckDB와 pg_duckdb로 PostgreSQL 분석 쿼리 100배 가속하기'
excerpt: 'PostgreSQL의 OLTP 안정성을 유지하면서 DuckDB의 컬럼나 엔진으로 분석 쿼리를 극적으로 가속하는 방법을 실전 벤치마크와 함께 살펴봅니다.'
date: '2026-02-14'
category: 'DATABASE'
tags: ['DuckDB', 'PostgreSQL', 'pg_duckdb', 'OLAP', 'Analytics']
featured: false
---

# DuckDB와 pg_duckdb로 PostgreSQL 분석 쿼리 100배 가속하기

## 들어가며: OLTP와 OLAP 사이의 오래된 딜레마

대부분의 프로덕션 시스템에서 PostgreSQL은 트랜잭션 처리(OLTP)의 왕좌를 차지하고 있습니다. 안정성, 확장성, 풍부한 생태계 덕분에 스타트업부터 대기업까지 광범위하게 사용되죠. 하지만 데이터가 수천만 건을 넘어가면서 분석 쿼리를 실행할 때 문제가 생깁니다. 월별 매출 집계, 코호트 분석, 대규모 조인 쿼리 같은 작업이 몇 분씩 걸리기 시작하면, 팀은 흔히 별도의 데이터 웨어하우스를 도입하는 방향으로 갑니다.

BigQuery, Snowflake, Redshift 같은 클라우드 웨어하우스를 붙이면 분석 성능은 해결되지만, ETL 파이프라인 구축과 유지보수라는 새로운 문제가 생깁니다. 데이터 동기화 지연, 스키마 변경 전파, 추가 인프라 비용까지 고려하면, 단순히 "분석 쿼리 좀 빠르게 돌리고 싶다"는 요구에 비해 솔루션이 과하게 무거워집니다.

여기서 DuckDB가 등장합니다. DuckDB는 임베디드 컬럼나 데이터베이스로, SQLite가 OLTP에서 하는 역할을 OLAP에서 수행합니다. 별도 서버 없이 프로세스 내에서 동작하면서도, 벡터화된 실행 엔진과 컬럼나 스토리지 덕분에 분석 쿼리에서 놀라운 성능을 보여줍니다. 그리고 2024년 말에 출시된 `pg_duckdb` 확장은 이 DuckDB 엔진을 PostgreSQL 내부에 직접 임베드합니다. PostgreSQL 클라이언트에서 평소처럼 SQL을 실행하면, 옵티마이저가 분석 쿼리를 자동으로 DuckDB 엔진으로 라우팅하는 것이죠.

이 글에서는 pg_duckdb의 아키텍처를 깊이 파고들고, 실전 벤치마크를 통해 실제로 어느 정도의 성능 향상을 기대할 수 있는지 검증합니다. 그리고 프로덕션에서 이 조합을 안전하게 운영하기 위한 구체적인 전략을 다룹니다.

## DuckDB가 분석 쿼리에서 빠른 이유

DuckDB의 성능 비결을 이해하려면, 전통적인 로우 기반 데이터베이스와 컬럼나 데이터베이스의 근본적인 차이를 알아야 합니다.

### 컬럼나 스토리지의 힘

PostgreSQL은 데이터를 행(row) 단위로 저장합니다. 한 행의 모든 컬럼이 디스크에 연속으로 배치되죠. 이 구조는 `SELECT * FROM users WHERE id = 42` 같은 포인트 조회에 최적입니다. 한 번의 디스크 읽기로 해당 행의 모든 데이터를 가져올 수 있으니까요.

반면 `SELECT AVG(amount) FROM orders WHERE created_at > '2025-01-01'`같은 분석 쿼리에서는 이야기가 달라집니다. 수백만 행 중 `amount`와 `created_at` 두 컬럼만 필요한데, PostgreSQL은 각 행의 모든 컬럼을 읽어야 합니다. 100개 컬럼이 있는 테이블에서 2개 컬럼만 쓸 때, 나머지 98개 컬럼의 데이터를 읽고 버리는 셈입니다.

DuckDB는 데이터를 열(column) 단위로 저장합니다. 같은 컬럼의 값들이 디스크에 연속으로 배치되므로, 필요한 컬럼만 정확히 읽을 수 있습니다. 위 쿼리에서 `amount`와 `created_at` 데이터만 스캔하니, I/O가 극적으로 줄어듭니다.

### 벡터화된 실행 엔진

DuckDB의 두 번째 비밀 무기는 벡터화된 쿼리 실행입니다. 전통적인 데이터베이스 엔진은 Volcano 모델을 사용합니다. 각 연산자가 한 번에 한 행씩 처리하는 방식이죠. 반면 DuckDB는 한 번에 2048개 행을 하나의 벡터로 묶어 처리합니다. 이는 현대 CPU의 SIMD 명령어와 캐시 라인 활용을 극대화합니다.

```sql
-- 이 쿼리가 실행될 때 내부적으로 일어나는 일
SELECT category, SUM(amount), COUNT(*)
FROM orders
WHERE status = 'completed'
GROUP BY category;

-- PostgreSQL (Volcano 모델):
--   1행 읽기 → 필터 → 해시맵 업데이트 → 1행 읽기 → 필터 → ...
--   행마다 함수 호출 오버헤드 발생

-- DuckDB (벡터화 실행):
--   2048행 벡터 읽기 → 벡터 전체 필터 (SIMD) → 벡터 전체 해시 → 벡터 전체 집계
--   함수 호출 1회로 2048행 처리
```

### 자동 병렬화

DuckDB는 쿼리를 자동으로 멀티코어에 분배합니다. 별도 설정 없이도 사용 가능한 모든 CPU 코어를 활용하여 테이블 스캔, 해시 조인, 집계를 병렬로 수행합니다. PostgreSQL도 Parallel Query를 지원하지만, `max_parallel_workers_per_gather` 설정이 보수적이고 모든 쿼리 패턴에서 병렬화가 작동하는 것은 아닙니다.

```sql
-- DuckDB의 병렬 처리 설정 확인
SELECT current_setting('threads');
-- 기본값: 시스템의 코어 수 (예: 8코어 머신이면 8)

-- PostgreSQL에서 병렬 처리 활성화 (튜닝 필요)
SET max_parallel_workers_per_gather = 4;
SET parallel_tuple_cost = 0.001;
-- 그래도 모든 쿼리에서 병렬화가 작동하지는 않음
```

### 압축 효율

컬럼나 스토리지는 압축에서도 유리합니다. 같은 컬럼의 값들은 데이터 타입이 동일하고 값의 분포가 유사하기 때문에, 딕셔너리 인코딩, 런 렝스 인코딩, 비트패킹 같은 압축 알고리즘이 매우 효과적으로 작동합니다. 실제로 DuckDB는 원본 대비 3~10배 압축률을 달성하는 경우가 많습니다. 압축된 데이터는 디스크 I/O를 줄일 뿐 아니라, 메모리 내에서도 캐시 효율을 높여 전체 성능을 끌어올립니다.

## pg_duckdb 아키텍처 깊이 보기

pg_duckdb는 PostgreSQL의 확장(extension) 메커니즘을 활용하여 DuckDB 엔진을 PostgreSQL 프로세스 내에 임베드합니다. 별도의 외부 프로세스나 네트워크 통신이 필요 없습니다.

### 설치와 기본 설정

```bash
# pg_duckdb 설치 (PostgreSQL 15, 16, 17 지원)
# 소스 빌드
git clone https://github.com/duckdb/pg_duckdb.git
cd pg_duckdb
make install

# 또는 apt/yum 패키지 (Ubuntu 예시)
sudo apt install postgresql-17-pg-duckdb
```

```sql
-- PostgreSQL에서 확장 활성화
CREATE EXTENSION pg_duckdb;

-- DuckDB 엔진 상태 확인
SELECT duckdb.version();
-- 'v1.1.3'

-- DuckDB 실행 활성화 (세션 레벨)
SET duckdb.execution = true;
```

### 쿼리 라우팅 메커니즘

pg_duckdb의 핵심은 쿼리 라우팅입니다. PostgreSQL의 플래너 후크(planner hook)를 통해 쿼리 계획 단계에서 개입합니다. 쿼리가 들어오면 pg_duckdb는 해당 쿼리가 DuckDB 엔진에서 실행 가능한지 판단하고, 가능하다면 DuckDB로 라우팅합니다.

```sql
-- 자동 라우팅 예시
-- 이 분석 쿼리는 자동으로 DuckDB 엔진으로 라우팅됨
EXPLAIN SELECT
    date_trunc('month', created_at) AS month,
    category,
    SUM(amount) AS total_revenue,
    COUNT(DISTINCT customer_id) AS unique_customers
FROM orders
WHERE created_at >= '2025-01-01'
GROUP BY 1, 2
ORDER BY 1, 3 DESC;

-- 실행 계획에서 "DuckDB Scan" 또는 "Custom Scan (DuckDB)" 확인 가능
```

### DuckDB 전용 테이블 생성

최대 성능을 위해서는 DuckDB 네이티브 컬럼나 포맷으로 테이블을 생성할 수 있습니다. 이 경우 PostgreSQL의 힙 스토리지 대신 DuckDB의 컬럼나 스토리지를 사용합니다.

```sql
-- DuckDB 네이티브 테이블 생성 (columnstore)
-- 이 테이블은 DuckDB 스토리지 엔진을 사용
CREATE TABLE analytics.events (
    event_id    BIGINT,
    user_id     BIGINT,
    event_type  TEXT,
    properties  JSONB,
    created_at  TIMESTAMPTZ
) USING duckdb;

-- 기존 PostgreSQL 테이블의 데이터를 DuckDB 테이블로 복사
INSERT INTO analytics.events
SELECT * FROM public.events
WHERE created_at >= '2025-01-01';

-- Parquet 파일에서 직접 로드도 가능
SELECT duckdb.install_extension('httpfs');

INSERT INTO analytics.events
SELECT * FROM duckdb.read_parquet('s3://my-bucket/events/*.parquet');
```

### PostgreSQL 테이블 직접 스캔

DuckDB 전용 테이블을 만들지 않아도, pg_duckdb는 기존 PostgreSQL 테이블을 직접 읽을 수 있습니다. PostgreSQL의 공유 버퍼를 통해 데이터를 읽은 뒤, DuckDB 엔진의 벡터화 실행으로 처리합니다. 이 경우 컬럼나 스토리지의 이점은 없지만, 벡터화 실행과 자동 병렬화의 이점은 그대로 누릴 수 있습니다.

```sql
-- 기존 PostgreSQL 테이블도 DuckDB 엔진으로 쿼리 가능
SET duckdb.execution = true;

-- PostgreSQL 히프 테이블을 DuckDB가 스캔
SELECT
    u.country,
    COUNT(*) AS order_count,
    AVG(o.total_amount) AS avg_order_value
FROM orders o
JOIN users u ON o.user_id = u.id
WHERE o.created_at >= '2025-06-01'
GROUP BY u.country
ORDER BY order_count DESC
LIMIT 20;
```

## 실전 벤치마크: PostgreSQL vs pg_duckdb

벤치마크 환경을 구성하고 실제 성능 차이를 측정해 보겠습니다.

### 테스트 환경

```
서버: AWS r6g.xlarge (4 vCPU, 32GB RAM, ARM64)
PostgreSQL: 17.2
pg_duckdb: 0.3.0 (DuckDB 1.1.3 기반)
데이터: 전자상거래 주문 데이터
  - orders: 5,000만 행 (약 28GB)
  - order_items: 1억 5,000만 행 (약 52GB)
  - users: 500만 행 (약 2GB)
  - products: 10만 행 (약 50MB)
```

### 테스트 데이터 생성

```sql
-- 테스트 데이터 생성 스크립트
CREATE TABLE orders (
    id          BIGSERIAL PRIMARY KEY,
    user_id     BIGINT NOT NULL,
    status      TEXT NOT NULL,
    total_amount NUMERIC(12,2),
    currency    TEXT DEFAULT 'USD',
    created_at  TIMESTAMPTZ NOT NULL,
    updated_at  TIMESTAMPTZ NOT NULL
);

-- 5000만 건 삽입 (generate_series 활용)
INSERT INTO orders (user_id, status, total_amount, currency, created_at, updated_at)
SELECT
    (random() * 5000000)::bigint + 1,
    (ARRAY['pending','completed','cancelled','refunded'])[floor(random()*4+1)::int],
    (random() * 500 + 5)::numeric(12,2),
    (ARRAY['USD','EUR','KRW','JPY'])[floor(random()*4+1)::int],
    timestamp '2023-01-01' + random() * interval '730 days',
    timestamp '2023-01-01' + random() * interval '730 days'
FROM generate_series(1, 50000000);

-- 인덱스 생성 (PostgreSQL 최적화)
CREATE INDEX idx_orders_created_at ON orders (created_at);
CREATE INDEX idx_orders_user_id ON orders (user_id);
CREATE INDEX idx_orders_status ON orders (status);
ANALYZE orders;
```

### 벤치마크 쿼리와 결과

**쿼리 1: 월별 매출 집계**

```sql
SELECT
    date_trunc('month', created_at) AS month,
    COUNT(*) AS order_count,
    SUM(total_amount) AS revenue,
    AVG(total_amount) AS avg_order_value
FROM orders
WHERE status = 'completed'
  AND created_at >= '2024-01-01'
GROUP BY 1
ORDER BY 1;
```

| 엔진 | 실행 시간 | 비고 |
|------|----------|------|
| PostgreSQL (cold) | 42.3초 | Seq Scan + HashAggregate |
| PostgreSQL (warm) | 18.7초 | 버퍼 캐시 히트 |
| pg_duckdb (PG 테이블) | 2.1초 | 벡터화 + 병렬 (4코어) |
| pg_duckdb (DuckDB 테이블) | 0.38초 | 컬럼나 + 벡터화 + 병렬 |

**쿼리 2: 코호트 리텐션 분석**

```sql
WITH first_purchase AS (
    SELECT
        user_id,
        date_trunc('month', MIN(created_at)) AS cohort_month
    FROM orders
    WHERE status = 'completed'
    GROUP BY user_id
),
monthly_activity AS (
    SELECT
        o.user_id,
        date_trunc('month', o.created_at) AS activity_month
    FROM orders o
    WHERE o.status = 'completed'
    GROUP BY o.user_id, date_trunc('month', o.created_at)
)
SELECT
    fp.cohort_month,
    EXTRACT(MONTH FROM AGE(ma.activity_month, fp.cohort_month))::int AS months_since,
    COUNT(DISTINCT ma.user_id) AS active_users
FROM first_purchase fp
JOIN monthly_activity ma ON fp.user_id = ma.user_id
WHERE fp.cohort_month >= '2024-01-01'
GROUP BY 1, 2
ORDER BY 1, 2;
```

| 엔진 | 실행 시간 | 비고 |
|------|----------|------|
| PostgreSQL (warm) | 3분 12초 | 해시 조인 + 큰 중간 결과셋 |
| pg_duckdb (PG 테이블) | 8.4초 | ~23배 가속 |
| pg_duckdb (DuckDB 테이블) | 1.2초 | ~160배 가속 |

**쿼리 3: 상위 고객 + 최근 주문 (윈도우 함수)**

```sql
SELECT * FROM (
    SELECT
        user_id,
        SUM(total_amount) AS lifetime_value,
        COUNT(*) AS total_orders,
        MAX(created_at) AS last_order_at,
        ROW_NUMBER() OVER (ORDER BY SUM(total_amount) DESC) AS rank
    FROM orders
    WHERE status = 'completed'
    GROUP BY user_id
) ranked
WHERE rank <= 1000;
```

| 엔진 | 실행 시간 | 비고 |
|------|----------|------|
| PostgreSQL (warm) | 28.5초 | Sort + WindowAgg |
| pg_duckdb (PG 테이블) | 3.2초 | ~9배 가속 |
| pg_duckdb (DuckDB 테이블) | 0.51초 | ~56배 가속 |

> **핵심 인사이트:** pg_duckdb로 기존 PostgreSQL 테이블을 스캔하는 것만으로도 9~23배 가속이 가능합니다. DuckDB 네이티브 테이블을 사용하면 56~160배까지 향상됩니다. 데이터 마이그레이션 없이 확장만 설치해도 즉각적인 효과를 볼 수 있다는 것이 핵심입니다.

## 프로덕션 적용 전략

벤치마크 결과가 인상적이지만, 프로덕션에서 pg_duckdb를 안전하게 운영하려면 몇 가지 전략이 필요합니다.

### 전략 1: 읽기 전용 리플리카에서 실행

가장 안전한 접근법은 pg_duckdb를 읽기 전용 리플리카에만 설치하는 것입니다. 프라이머리 서버의 OLTP 워크로드에 영향을 주지 않으면서, 리플리카에서 분석 쿼리를 가속할 수 있습니다.

```sql
-- 리플리카에서 pg_duckdb 설정
-- postgresql.conf (리플리카)
-- shared_preload_libraries = 'pg_duckdb'
-- duckdb.execution = on

-- 리플리카에서 분석 쿼리 실행
-- 애플리케이션 레벨에서 읽기 쿼리를 리플리카로 라우팅
-- 예: Rails의 database.yml에서 replica 설정
```

```yaml
# Rails 예시: config/database.yml
production:
  primary:
    url: postgresql://primary-host:5432/myapp
  replica:
    url: postgresql://replica-with-duckdb:5432/myapp
    replica: true
```

### 전략 2: 하이브리드 테이블 전략

자주 분석하는 대용량 테이블만 DuckDB 스토리지로 전환하고, 나머지는 PostgreSQL 그대로 유지합니다.

```sql
-- 분석 전용 스키마 구성
CREATE SCHEMA analytics;

-- 핫 데이터: PostgreSQL (최근 3개월, OLTP 활발)
-- 콜드 데이터: DuckDB 테이블 (3개월 이전, 분석 전용)

-- 콜드 데이터 마이그레이션 함수
CREATE OR REPLACE FUNCTION migrate_to_duckdb(cutoff_date TIMESTAMPTZ)
RETURNS void AS $$
BEGIN
    -- 콜드 데이터를 DuckDB 테이블로 이동
    INSERT INTO analytics.orders_cold
    SELECT * FROM public.orders
    WHERE created_at < cutoff_date
    AND id NOT IN (SELECT id FROM analytics.orders_cold);

    -- 원본에서 삭제 (선택사항)
    -- DELETE FROM public.orders WHERE created_at < cutoff_date;
END;
$$ LANGUAGE plpgsql;

-- 통합 뷰 (핫 + 콜드)
CREATE VIEW analytics.orders_all AS
SELECT * FROM public.orders          -- 최근 3개월 (PostgreSQL)
UNION ALL
SELECT * FROM analytics.orders_cold; -- 3개월 이전 (DuckDB)
```

### 전략 3: 메모리 관리

DuckDB는 메모리를 적극적으로 사용합니다. PostgreSQL의 `shared_buffers`와 리소스 경합이 발생할 수 있으므로 적절한 설정이 필요합니다.

```sql
-- DuckDB 메모리 제한 설정
SET duckdb.memory_limit = '8GB';  -- 전체 RAM의 25% 정도 권장

-- PostgreSQL 설정과 조화
-- shared_buffers = 8GB    (전체 32GB 중 25%)
-- effective_cache_size = 20GB
-- DuckDB memory_limit = 8GB (나머지에서 할당)
-- OS 캐시용: 약 4GB 여유

-- 쿼리별 메모리 사용량 모니터링
SELECT duckdb.query_memory_usage();
```

### 전략 4: Parquet와 오브젝트 스토리지 연동

pg_duckdb의 강력한 기능 중 하나는 외부 Parquet 파일을 직접 쿼리할 수 있다는 것입니다. S3나 GCS에 저장된 데이터 레이크를 PostgreSQL에서 바로 분석할 수 있습니다.

```sql
-- S3 접근 설정
SELECT duckdb.install_extension('httpfs');
SELECT duckdb.execute($$
    SET s3_region = 'ap-northeast-2';
    SET s3_access_key_id = 'AKIA...';
    SET s3_secret_access_key = '...';
$$);

-- S3의 Parquet 파일 직접 쿼리
SELECT
    date_trunc('day', event_time) AS day,
    event_type,
    COUNT(*) AS event_count
FROM duckdb.read_parquet('s3://my-data-lake/events/2025/**/*.parquet')
WHERE event_time >= '2025-01-01'
GROUP BY 1, 2
ORDER BY 1, 3 DESC;

-- PostgreSQL 테이블과 S3 Parquet 조인도 가능!
SELECT
    u.email,
    u.name,
    e.event_count
FROM users u
JOIN (
    SELECT
        user_id,
        COUNT(*) AS event_count
    FROM duckdb.read_parquet('s3://my-data-lake/events/2025/**/*.parquet')
    GROUP BY user_id
    HAVING COUNT(*) > 100
) e ON u.id = e.user_id;
```

## DuckDB 독립 실행 vs pg_duckdb: 언제 무엇을

pg_duckdb가 만능은 아닙니다. DuckDB를 독립적으로 사용하는 것이 더 적절한 경우도 있습니다.

### pg_duckdb가 적합한 경우

pg_duckdb는 이미 PostgreSQL 중심의 아키텍처를 가지고 있을 때 빛납니다. 기존 PostgreSQL 테이블을 변경 없이 분석 가속할 수 있고, 하나의 SQL 인터페이스로 OLTP와 OLAP를 모두 처리할 수 있습니다. 애플리케이션 코드 변경이 최소화되며, 기존 PostgreSQL의 권한 관리, 연결 풀링, 모니터링 인프라를 그대로 활용할 수 있습니다.

```python
# 애플리케이션 코드 변경 없이 분석 쿼리 가속
# 기존 ORM 쿼리가 자동으로 DuckDB 엔진으로 라우팅됨

# Django 예시
from django.db import connection

# 이 쿼리는 pg_duckdb가 자동으로 DuckDB 엔진으로 실행
with connection.cursor() as cursor:
    cursor.execute("""
        SELECT date_trunc('week', created_at) AS week,
               COUNT(*) AS orders,
               SUM(total_amount) AS revenue
        FROM orders
        WHERE created_at >= %s
        GROUP BY 1
        ORDER BY 1
    """, ['2025-01-01'])
    weekly_stats = cursor.fetchall()
```

### 독립 DuckDB가 적합한 경우

반면, 데이터 사이언스 팀이 로컬에서 탐색적 분석을 수행하거나, Parquet/CSV 파일 기반의 데이터 파이프라인을 구축할 때는 독립 DuckDB가 더 적합합니다. Jupyter Notebook이나 Python 스크립트에서 직접 사용할 수 있어 개발 속도가 빠릅니다.

```python
import duckdb

# 로컬 파일 분석 (PostgreSQL 불필요)
conn = duckdb.connect()

# CSV 파일 바로 분석
result = conn.execute("""
    SELECT
        product_category,
        SUM(revenue) AS total_revenue,
        AVG(conversion_rate) AS avg_conversion
    FROM read_csv_auto('marketing_data_*.csv')
    GROUP BY product_category
    ORDER BY total_revenue DESC
""").fetchdf()  # Pandas DataFrame으로 반환

# Parquet 파일 변환 (ETL)
conn.execute("""
    COPY (
        SELECT * FROM read_csv_auto('raw_logs/*.csv')
        WHERE event_date >= '2025-01-01'
    ) TO 'processed/events.parquet' (FORMAT PARQUET, COMPRESSION ZSTD)
""")
```

## 주의사항과 제한사항

pg_duckdb를 프로덕션에 도입하기 전에 반드시 알아야 할 제한사항들이 있습니다.

### 트랜잭션 격리

DuckDB 테이블(`USING duckdb`)은 PostgreSQL의 MVCC와 완벽히 통합되지 않습니다. 동시에 여러 트랜잭션이 같은 DuckDB 테이블을 수정하면 충돌이 발생할 수 있습니다. 따라서 DuckDB 테이블은 주로 읽기 위주의 분석 데이터에 사용하는 것이 좋습니다.

```sql
-- ❌ DuckDB 테이블에 동시 쓰기는 위험
-- 트랜잭션 A
BEGIN;
INSERT INTO analytics.events_duckdb SELECT ...;

-- 트랜잭션 B (동시 실행 시 문제 가능)
BEGIN;
INSERT INTO analytics.events_duckdb SELECT ...;

-- ✅ 배치 로드 후 읽기 전용으로 사용
-- 정해진 시간에 배치로 데이터 로드
-- 나머지 시간에는 읽기 전용 분석 쿼리
```

### 지원되지 않는 기능

pg_duckdb는 아직 활발히 개발 중이며, 일부 PostgreSQL 기능을 지원하지 않습니다. 예를 들어 특정 PostgreSQL 확장 타입(`PostGIS`, `pg_trgm` 등)은 DuckDB 엔진에서 처리할 수 없습니다. 이 경우 자동으로 PostgreSQL 엔진으로 폴백합니다. 또한 `INSERT`, `UPDATE`, `DELETE`는 DuckDB 테이블에서만 가능하며, 일반 PostgreSQL 테이블에 대한 DML은 항상 PostgreSQL 엔진이 처리합니다.

```sql
-- pg_duckdb에서 지원하지 않는 기능 예시
-- PostGIS 함수 → PostgreSQL로 폴백
SELECT ST_Distance(
    ST_MakePoint(lng, lat),
    ST_MakePoint(127.0, 37.5)
)
FROM locations;  -- PostgreSQL 엔진이 처리

-- JSONB 경로 쿼리 → 부분 지원
SELECT properties->>'event_name'
FROM events;  -- DuckDB가 처리 가능

SELECT jsonb_path_query(properties, '$.items[*].price')
FROM events;  -- 복잡한 경로는 PostgreSQL로 폴백될 수 있음
```

### 버전 호환성

pg_duckdb의 버전과 PostgreSQL 버전의 호환성 매트릭스를 반드시 확인해야 합니다. 2025년 말 기준으로 PostgreSQL 15, 16, 17을 공식 지원하며, PostgreSQL 메이저 버전 업그레이드 시 pg_duckdb도 함께 재빌드해야 합니다.

## 실전 운영 팁

### 모니터링 설정

```sql
-- DuckDB 쿼리 실행 로그 활성화
SET duckdb.log_queries = true;

-- 어떤 쿼리가 DuckDB로 라우팅되는지 확인
-- pg_stat_statements와 함께 사용
SELECT
    query,
    calls,
    mean_exec_time,
    total_exec_time
FROM pg_stat_statements
WHERE query LIKE '%DuckDB%'  -- DuckDB 실행 쿼리 필터
ORDER BY total_exec_time DESC
LIMIT 20;

-- DuckDB 메모리 사용량 모니터링
SELECT * FROM duckdb.memory_usage();
```

### 자동 데이터 동기화

```sql
-- pg_cron으로 야간 배치 동기화 설정
-- 매일 새벽 3시에 전날 데이터를 DuckDB 테이블로 복사
SELECT cron.schedule(
    'sync-orders-to-duckdb',
    '0 3 * * *',
    $$
    INSERT INTO analytics.orders_duckdb
    SELECT * FROM public.orders
    WHERE created_at >= CURRENT_DATE - INTERVAL '1 day'
      AND created_at < CURRENT_DATE
    ON CONFLICT (id) DO NOTHING;
    $$
);
```

### 쿼리 성능 비교 함수

```sql
-- PostgreSQL vs DuckDB 실행 시간 비교 유틸리티
CREATE OR REPLACE FUNCTION compare_engines(query_text TEXT)
RETURNS TABLE(engine TEXT, exec_time_ms FLOAT) AS $$
DECLARE
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
BEGIN
    -- PostgreSQL 엔진
    SET duckdb.execution = false;
    start_time := clock_timestamp();
    EXECUTE query_text;
    end_time := clock_timestamp();
    engine := 'PostgreSQL';
    exec_time_ms := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    RETURN NEXT;

    -- DuckDB 엔진
    SET duckdb.execution = true;
    start_time := clock_timestamp();
    EXECUTE query_text;
    end_time := clock_timestamp();
    engine := 'DuckDB';
    exec_time_ms := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    RETURN NEXT;
END;
$$ LANGUAGE plpgsql;

-- 사용 예시
SELECT * FROM compare_engines(
    'SELECT date_trunc(''month'', created_at), COUNT(*) FROM orders GROUP BY 1'
);
```

## 마치며: ETL 없는 분석의 시대

pg_duckdb는 데이터베이스 생태계에서 일어나고 있는 중요한 패러다임 전환을 보여줍니다. 과거에는 OLTP와 OLAP가 완전히 분리된 시스템이어야 한다는 것이 상식이었습니다. 트랜잭션 데이터베이스에서 분석 쿼리를 실행한다는 것은 성능 저하와 운영 리스크를 의미했죠.

DuckDB가 이 공식을 바꿨습니다. 컬럼나 스토리지, 벡터화 실행, 자동 병렬화라는 세 가지 기술적 기반 위에서, 별도의 데이터 웨어하우스 없이도 수천만~수억 건의 데이터를 초 단위로 분석할 수 있게 되었습니다. pg_duckdb는 이 혁신을 PostgreSQL 사용자가 가장 쉽게 누릴 수 있는 경로를 제공합니다.

물론 pg_duckdb가 Snowflake나 BigQuery를 완전히 대체할 수 있는 것은 아닙니다. 페타바이트 규모의 데이터, 수백 명의 동시 분석 사용자, 복잡한 데이터 거버넌스가 필요하다면 전용 웨어하우스가 여전히 정답입니다. 하지만 많은 팀에서 "분석 쿼리가 좀 느려서" 도입하는 ETL 파이프라인과 별도 웨어하우스는, pg_duckdb 확장 하나로 불필요해질 수 있습니다.

PostgreSQL에 `CREATE EXTENSION pg_duckdb` 한 줄이면, 복잡한 ETL 파이프라인 구축 없이 즉시 분석 성능을 수십 배 끌어올릴 수 있습니다. 이것이 바로 "ETL 없는 분석"의 시작이며, 2026년에 데이터 엔지니어링 분야에서 가장 실용적인 변화 중 하나가 될 것입니다.
